<!DOCTYPE html>
<html lang="en">

<head>
    

    
    

    
    
    
    

    
    

    <title>Ollama! My Llama! - Ray Riga</title>

    <!-- Meta Tags -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <meta name="title" content="Ollama! My Llama! - Ray Riga" />
    <meta name="description" content="" />
    <meta name="keywords" content="Python, SQL, Audio, Ranked Choice, Semantic Merge Conflicts, LiveView, Elixir, Phoenix, Data Engineering" />

    <!-- Favicon -->
    <link rel="apple-touch-icon-precomposed"
        sizes="57x57" href="favicon-apple-touch-114.png">

    <link rel="apple-touch-icon-precomposed"
        sizes="114x114" href="favicon-apple-touch-114.png">

    <link rel="apple-touch-icon-precomposed"
        sizes="72x72" href="favicon-apple-touch-144.png">

    <link rel="apple-touch-icon-precomposed"
        sizes="144x144" href="favicon-apple-touch-144.png">

    <link rel="icon" type="image/vnd.microsoft.icon"
        sizes="32x32 48x48" href="favicon.ico">

    <link rel="icon" sizes="128x128" href="favicon.icns">

    <link rel="icon" href="favicon.png" type="image/x-icon">

    <link rel="icon" type="image/png" sizes="16x16" href="https://rayriga.com/favicons/favicon-16x16.png?h=c5f8a0e9a12e9b7c763f">

    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="theme-color" content="#ffffff">

    <!-- Open Graph Protocol -->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https:&#x2F;&#x2F;rayriga.com&#x2F;blog&#x2F;ollama-my-llama&#x2F;" />
    <meta property="og:title" content="Ollama! My Llama! - Ray Riga" />
    <meta property="og:description" content="" />
    <meta property="og:image" content="https://rayriga.com/imgs/og_img.png?h=192f8b4f81959b7bd101" />

    <link rel="alternate" type="application/rss+xml" title="RSS feed" href="https://rayriga.com/rss.xml" />

    <!-- Stylesheets -->
    <link href="https://rayriga.com/styles/main.css?h=d0a54e6c785a02955710" rel="stylesheet" type="text/css" />

    <!-- Plausible Analytics -->
    <script defer data-domain="rayriga.com" src="https://plausible-fb9lc-u1102.vm.elestio.app/js/script.js"></script>

    
    
</head>

<body>
    <div class="antialiased dark:bg-gray-100 dark:text-gray-800">
        <div class="flex flex-col min-h-screen space-y-12">
            <header class="container flex items-center justify-between w-full max-w-3xl px-6 py-10 mx-auto xl:max-w-5xl">
                <a rel="noopener noreferrer" href="/" class="block h-6 text-5xl font-extrabold">RAY RIGA</a>
            </header>
            <main class="container flex-1 max-w-3xl px-6 mx-auto space-y-12 xl:max-w-5xl">
                
<div class="markdown">
	<h1 class="title">
	  Ollama! My Llama!
	</h1>
	<p class="subtitle"><strong>2024-09-29</strong></p>
	<p>The perks of private open source AI toolchains</p>
<h2 id="first-touch">First Touch</h2>
<p>My first extended experience with modern AI was a &quot;fine-tuned ChatGPT&quot; which was part of a SaaS (Software-as-a-Service) being used for my latest startup venture. This &quot;talking rubber duck&quot; of sorts was helpful in that it provided not the solution, but a reliable <em>catalysis</em> of the correct approach to any given challenge. Alas, this SaaS was not cheap, and the subscription expired.</p>
<p>ChatGPT is an example of a Large Language Model, or LLM. These models are trained on specialized hardware: massive supercomputer clusters far out of the budget of the typical sole proprietor, startup, or SMB. ChatGPT is a proprietary service of the company <a href="https://openai.com">OpenAI</a>, which is a strange name for a company with secret code. To the contrary, some other companies such as Meta open source their LLMs, and some even open source their training data. Meta's series of general purpose LLMs, <a href="https://github.com/meta-llama/llama-models">Llama</a>, is one of the best known. Another AI company called <a href="https://huggingface.co">Hugging Face</a> is known for hosting various open source AI models and training data including Llama to download for free. </p>
<p>The models themselves do not require the training data to run. In other words, once a model is trained, all one needs is some less-prohibitively-expensive specialized hardware to run open source AI models at home (or on premise) using an entirely open source and private toolchain. Sounds easy, right? Sorta.</p>
<h2 id="the-less-prohibitively-expensive-specialized-hardware">The Less-Prohibitively-Expensive Specialized Hardware</h2>
<p>The thing about these models is, they require specialized hardware to run. If you happen to be a PC gamer, a reasonably modern GPU might be enough to get you going, but I don't fit that bill. I am, however, a &quot;homelab&quot; tinkerer, meaning I like to run servers at home. I've run specialized hardware at home over the years for everything from bulk vinyl digitization to cryptocurrency mining to an unmetered on-premise geocoding API service. My latest homelab project is something called a &quot;compute module cluster&quot;: a small-scale version of the distributed computing systems used in enterprises and data centers with container orchestration systems like <a href="https://kubernetes.io">Kubernetes</a>. The compute module cluster, called a <a href="https://turingpi.com">Turing Pi</a>, allows for experiments with these systems at home, at no additional cost besides electricityâ€”and one of the benefits of these small-scale compute module clusters is their energy efficiency. In fact, the whole cluster is powered by something called a PicoPSU which maxes out at only 160W.</p>
<p>With a compute cluster already in hand, it was time to learn more about the available LLM-ready GPU compute modules on the market, and I soon discovered the <a href="https://developer.nvidia.com/embedded-computing">NVIDIA Jetson</a> line of products. After some research, I selected a module called the Orin NX 16GB, a midrange model in the line. According to the spec sheet, this module can handle &quot;Up to 100 (Sparse) INT8 TOPs and 50 (Dense) INT8 TOPs,&quot; for a retail price of under $1,000. What are TOPs? Trillions of Operations Per second. In this case, 8-bit integer operations. In other words, this unassuming little RAM-looking chip is a BEAST. In practice, this module is able to run LLMs with 8 billion parameters while barely breaking a sweat.</p>
<h2 id="meet-orin-jetson">Meet Orin Jetson</h2>
<p>The form factor of the Orin NX is the correct match for the Turing Pi compute cluster. So, I plugged it in and started trying to flash it (in other words, set it up). Doing so was a minor ordeal of bare metal installations of Ubuntu 20.04 and 22.04 back and forth, and switching back and forth between the Turing Pi and a dedicated carrier board for each attempt, and cross-referencing documentation from Stack Overflow, NVIDIA Developer Forums, Turing Pi Discord Forums, and GitHub Gists. This was a summer of bleeding edge open source development for Orin hardware. But, I got it done.</p>
<p>Once the Orin was running in the Turing Pi cluster, it was time to install some LLM software. Initial attempts to directly install and run an open source program called <code>ollama</code> as a server failed. Fortunately, there's <code>jetson-containers</code>. This is a Docker-based open source package that allows turnkey access to not only <code>ollama</code> but many other open source AI programs as well, on Jetson hardware. Once <code>jetson-containers</code> was set up, running <code>ollama</code> as a server was easy. And with <code>ollama</code>, it's just as easy to choose from literally thousands of open source LLMs, AI code completion models, and computer vision models. </p>
<h2 id="the-many-clients-of-ollama">The Many Clients of Ollama</h2>
<p>With the <code>ollama</code> server running on the Orin and exposed to the internal local area network on a custom port, it was time to set up some remote clients. First, for my Mac and iOS devices, I installed <a href="https://github.com/AugustDev/enchanted">Enchanted</a>, an open source GUI for <code>ollama</code> written in Swift. This allowed for ongoing conversations with a number of models from everyday devices while at home. I can even ask questions (or, in LLM terms, prompts) to Enchanted via speaking.</p>
<p>Next up was the code editor. <a href="https://www.continue.dev">Continue</a> is an open source AI code assistant that easily integrates with both <a href="https://vscodium.com">VS Codium</a> (the open source version of Microsoft's VS Code) and the local <code>ollama</code> server. </p>
<p>With that, there are now three ways to interact with this private, fully open source toolchain of home AI:</p>
<ol>
<li>Speak or type prompts to various models (usually <code>llama3.1</code> at the moment) via Enchanted</li>
<li>Use code suggestion and code completion features via various models (usually <code>deepseek-coder-v2</code> at the moment) from VS Codium with Continue</li>
<li>Directly <code>ssh</code> into the Jetson module to upgrade <code>jetson-containers</code> as needed and manage models via the command line <code>ollama</code> client</li>
</ol>
<h2 id="conclusion">Conclusion</h2>
<p>In all honesty, there were several failed attempts over as many months that occurred with setting up this Jetson module before the events described above. There was even a moment of doubt and regret where I thought I'd never get it working. Now, I no longer doubt nor regret the value of this ambitious project. In fact, I like having my very own talking rubber duck!</p>

</div>

            </main>
            <footer class="container flex flex-col items-center max-w-3xl px-6 mx-auto xl:max-w-5xl">
                <div class="flex mb-3 space-x-4">
                    <a target="_blank" rel="noopener noreferrer" href="https://github.com/rayrrr" class="text-sm">
                        <span class="sr-only">github</span>
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 fill-current dark:text-sky-600">
                            <path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path>
                        </svg>
                    </a>
                    <a target="_blank" rel="noopener noreferrer" href="https://facebook.com/rayriga" class="text-sm">
                        <span class="sr-only">facebook</span>
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="w-6 h-6 fill-current dark:text-sky-600">
                            <path d="M24 12.073c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.99 4.388 10.954 10.125 11.854v-8.385H7.078v-3.47h3.047V9.43c0-3.007 1.792-4.669 4.533-4.669 1.312 0 2.686.235 2.686.235v2.953H15.83c-1.491 0-1.956.925-1.956 1.874v2.25h3.328l-.532 3.47h-2.796v8.385C19.612 23.027 24 18.062 24 12.073z"></path>
                        </svg>
                    </a>
                    <a target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/rayriga" class="text-sm">
                        <span class="sr-only">linkedin</span>
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 fill-current dark:text-sky-600">
                            <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path>
                        </svg>
                    </a>
                </div>
            </footer>
        </div>
    </div>
</body>

</html>
